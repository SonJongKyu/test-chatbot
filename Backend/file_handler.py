# --------------------------------------------------
# File: ~/RAG_Chatbot/Backend/file_handler.py
# Description: PDF / CSV í…ìŠ¤íŠ¸ ì¶”ì¶œ + ì „ëžµ ê¸°ë°˜ ì²­í‚¹ ì—”ì§„
# --------------------------------------------------

import fitz  # PyMuPDF
import re
import csv
import os
import json
from typing import List, Dict

BASE_DIR = os.path.join(os.path.expanduser("~"), "RAG_Chatbot")
CONFIG_PATH = os.path.join(BASE_DIR, "chunk_config.json")

# ========== ê¸°ë³¸ CONFIG ==========
DEFAULT_CONFIG = {
    "default": {
        "strategy": "regular",
        "chunk_size": 800,
        "overlap": 80
    },
    "pdf": {},
    "csv": {}
}

def load_config():
    if not os.path.exists(CONFIG_PATH):
        return DEFAULT_CONFIG
    try:
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return DEFAULT_CONFIG


# ========== PDF íŽ˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ==========
def pdf_to_text_with_page(pdf_path: str, file_name: str) -> List[Dict]:
    doc = fitz.open(pdf_path)
    pages = []
    for page in doc:
        text = page.get_text()
        text = re.sub(r"\s+", " ", text).strip()
        pages.append({
            "page_no": page.number + 1,
            "text": text,
            "file_name": file_name
        })
    doc.close()
    return pages


# ========== CSV â†’ í…ìŠ¤íŠ¸ ==========
def csv_to_text(file_path: str) -> str:
    rows = []
    with open(file_path, newline="", encoding="utf-8") as csvfile:
        reader = csv.reader(csvfile)
        for row in reader:
            rows.append(",".join(row))
    return "\n".join(rows)


# --------------------------------------------------
# ðŸ”¥ ì „ëžµ ê¸°ë°˜ ì²­í‚¹ ì—”ì§„
# --------------------------------------------------

def get_chunk_strategy(file_name: str):
    cfg = load_config()
    ext = "pdf" if file_name.lower().endswith(".pdf") else "csv"
    return cfg.get(ext, {}).get(file_name, cfg.get("default", {}))


# regular ì „ëžµ ìœ ì§€
def chunk_regular(text: str, cfg) -> List[Dict]:
    chunk_size = cfg.get("chunk_size", 800)
    overlap = cfg.get("overlap", 80)
    blocks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        blocks.append({"text": text[start:end]})
        start += max(chunk_size - overlap, 1)
    return blocks

# --------------------------------------------------
# ðŸ”¥ ë²•ë¥  ì¡°ë¬¸ íŒŒì„œ (ì¡° / í•­ / í˜¸ ë‹¨ìœ„ ì²­í‚¹)
# --------------------------------------------------
def parse_law_structure(text: str) -> List[Dict]:
    """ì¡° / í•­ / í˜¸ ë‹¨ìœ„ ë¶„ë¦¬ â†’ chapter/title/text êµ¬ì¡°"""
    article_pattern = r"(ì œ\d+ì¡°)\s*\((.*?)\)"
    articles = list(re.finditer(article_pattern, text))
    results = []

    for i, match in enumerate(articles):
        chapter = match.group(1)
        title = match.group(2)
        start = match.start()
        end = articles[i + 1].start() if i + 1 < len(articles) else len(text)
        body = text[start:end].strip()

        # í•­Â·í˜¸ ë‹¨ìœ„ ë¶„ë¦¬
        sub_items = re.split(r"\s+(\d+\.\s*)", body)
        if len(sub_items) > 1:
            merged = []
            buffer = ""
            for part in sub_items:
                if re.match(r"\d+\.\s*", part):
                    if buffer:
                        merged.append(buffer)
                    buffer = part
                else:
                    buffer += part
            if buffer:
                merged.append(buffer)

            for block in merged:
                results.append({
                    "chapter": chapter,
                    "title": title,
                    "text": block.strip()
                })
        else:
            results.append({
                "chapter": chapter,
                "title": title,
                "text": body
            })
    return results

# law ì „ëžµ (ê¸°ì¡´ ìœ ì§€)
def chunk_law(text: str) -> List[Dict]:
    return parse_law_structure(text)


# CSV ì „ëžµ (ê¸°ì¡´ ìœ ì§€)
def chunk_column_record(text: str, cfg) -> List[Dict]:
    mapping = cfg.get("mapping", {})
    rows = [line.split(",") for line in text.splitlines() if line.strip()]

    chunks = []
    for row in rows:
        obj = {}
        for key, idx in mapping.items():
            obj[key] = row[idx] if idx < len(row) else None
        chunks.append(obj)
    return chunks


# --------------------------------------------------
# ðŸ”¥ ìƒˆë¡œ ì¶”ê°€: PDF íŽ˜ì´ì§€ë¥¼ 1ê°œì˜ ì²­í¬ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
# --------------------------------------------------
def chunk_page(text: str) -> List[Dict]:
    return [{"text": text}]   # íŽ˜ì´ì§€ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ë°˜í™˜


# --------------------------------------------------
# apply_chunk_strategy â†’ ê¸°ì¡´ ìœ ì§€ + page ì „ëžµ 1ì¤„ë§Œ ì¶”ê°€
# --------------------------------------------------
def apply_chunk_strategy(raw_text: str, file_name: str) -> List[Dict]:
    cfg = get_chunk_strategy(file_name)
    strategy = cfg.get("strategy", "regular")

    if strategy == "law":
        return chunk_law(raw_text)
    elif strategy == "column_record":
        return chunk_column_record(raw_text, cfg)
    elif strategy == "page":
        return chunk_page(raw_text)         # ðŸ”¥ ì¶”ê°€ëœ íŽ˜ì´ì§€ ì „ëžµ
    else:
        return chunk_regular(raw_text, cfg)


# í•˜ìœ„ í˜¸í™˜ ìœ ì§€
def chunk_text_dynamic(text: str, file_name: str) -> List[Dict]:
    return apply_chunk_strategy(text, file_name)

chunk_text = chunk_text_dynamic
